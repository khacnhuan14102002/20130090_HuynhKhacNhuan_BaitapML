{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khacnhuan14102002/20130090_HuynhKhacNhuan_BaitapML/blob/main/Lab_4_20130090_HuynhKhacNhuan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to continous dealing with **Logistic Regression**, **kNN**, and **Decision Tree** alogirthms applied to classification tasks. \n",
        "\n",
        "*   **Deadline: 23:59, 12/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/MachineLearning'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xhCtxyIrRz2",
        "outputId": "a32c722e-01e4-431b-ad7c-352eda2e4fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/MachineLearning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "vzCbbPEhsCN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Apply **LogisticRegression** to iris dataset which aims at classifying species of iris based on sepal_length (chiều dài đài hoa), sepal_width, petal_length (chiều dài cánh hoa), petal_width. The species are '**setosa**' '**versicolor**' and '**virginica**'. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "data4 = datasets.load_iris()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "from sklearn import datasets\n",
        "data4 = datasets.load_iris()"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data4.data\n",
        "y = data4.target"
      ],
      "metadata": {
        "id": "MXCg3JuAskOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "a5z9_0XLvW-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Bs-pR0rw90L",
        "outputId": "e527eaca-fdba-49b7-cd9d-3b91ba8661d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
              " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': 'iris.csv',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VKJn2OB_xN6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "cc3ae6ea-88e8-4304-84da-770acdf28086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "E_jRKBHyZ5pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "RRiq12pJZ_6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score:', accuracy_score(y_test, y_pred))\n",
        "print('Classification report:', classification_report(y_test, y_pred))\n",
        "print('Confusion matrix:', confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuhqnycVaDy5",
        "outputId": "e7de05a7-db72-497f-a00e-16c52113eeda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 1.0\n",
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Confusion matrix: [[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "Apply LogisticRegression to **MNIST** dataset (mnist.csv) which aims at classifying handwritten digits. Dataset includes 784 pixels values of images (28x28). \n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "# load the MNIST digits dataset\n",
        "mnist = datasets.load_digits()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = datasets.load_digits()"
      ],
      "metadata": {
        "id": "_xhPpF5b033h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = mnist.data\n",
        "y = mnist.target"
      ],
      "metadata": {
        "id": "Sa4u42i0fhFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CXOhWzIMgjfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy5c7qJ2gpdU",
        "outputId": "ebcd7b73-8785-457b-e13f-1a8a59c57d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "        ...,\n",
              "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
              " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
              " 'frame': None,\n",
              " 'feature_names': ['pixel_0_0',\n",
              "  'pixel_0_1',\n",
              "  'pixel_0_2',\n",
              "  'pixel_0_3',\n",
              "  'pixel_0_4',\n",
              "  'pixel_0_5',\n",
              "  'pixel_0_6',\n",
              "  'pixel_0_7',\n",
              "  'pixel_1_0',\n",
              "  'pixel_1_1',\n",
              "  'pixel_1_2',\n",
              "  'pixel_1_3',\n",
              "  'pixel_1_4',\n",
              "  'pixel_1_5',\n",
              "  'pixel_1_6',\n",
              "  'pixel_1_7',\n",
              "  'pixel_2_0',\n",
              "  'pixel_2_1',\n",
              "  'pixel_2_2',\n",
              "  'pixel_2_3',\n",
              "  'pixel_2_4',\n",
              "  'pixel_2_5',\n",
              "  'pixel_2_6',\n",
              "  'pixel_2_7',\n",
              "  'pixel_3_0',\n",
              "  'pixel_3_1',\n",
              "  'pixel_3_2',\n",
              "  'pixel_3_3',\n",
              "  'pixel_3_4',\n",
              "  'pixel_3_5',\n",
              "  'pixel_3_6',\n",
              "  'pixel_3_7',\n",
              "  'pixel_4_0',\n",
              "  'pixel_4_1',\n",
              "  'pixel_4_2',\n",
              "  'pixel_4_3',\n",
              "  'pixel_4_4',\n",
              "  'pixel_4_5',\n",
              "  'pixel_4_6',\n",
              "  'pixel_4_7',\n",
              "  'pixel_5_0',\n",
              "  'pixel_5_1',\n",
              "  'pixel_5_2',\n",
              "  'pixel_5_3',\n",
              "  'pixel_5_4',\n",
              "  'pixel_5_5',\n",
              "  'pixel_5_6',\n",
              "  'pixel_5_7',\n",
              "  'pixel_6_0',\n",
              "  'pixel_6_1',\n",
              "  'pixel_6_2',\n",
              "  'pixel_6_3',\n",
              "  'pixel_6_4',\n",
              "  'pixel_6_5',\n",
              "  'pixel_6_6',\n",
              "  'pixel_6_7',\n",
              "  'pixel_7_0',\n",
              "  'pixel_7_1',\n",
              "  'pixel_7_2',\n",
              "  'pixel_7_3',\n",
              "  'pixel_7_4',\n",
              "  'pixel_7_5',\n",
              "  'pixel_7_6',\n",
              "  'pixel_7_7'],\n",
              " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
              "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
              "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
              "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
              "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
              "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
              "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
              "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
              "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
              "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
              "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
              " \n",
              "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
              "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
              "         ...,\n",
              "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
              "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
              "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
              " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logre = LogisticRegression()\n",
        "logre.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "mv7g6ZKBguUh",
        "outputId": "e4bf1df3-ad75-4936-caa0-ef47f8a1397d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = logre.predict(X_test)"
      ],
      "metadata": {
        "id": "q62DXLCbg1Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "iCXkxY40hCdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score:', accuracy_score(y_test, y_pred))\n",
        "print('Classification report:', classification_report(y_test, y_pred))\n",
        "print('Confusion matrix:', confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt83TQMphHE-",
        "outputId": "33323a0c-412f-47f2-d58f-63e1fafbcb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.9694444444444444\n",
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       0.97      1.00      0.98        28\n",
            "           2       0.97      1.00      0.99        33\n",
            "           3       0.97      0.97      0.97        34\n",
            "           4       1.00      0.96      0.98        46\n",
            "           5       0.92      0.94      0.93        47\n",
            "           6       0.94      0.97      0.96        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       0.97      0.97      0.97        30\n",
            "           9       0.97      0.95      0.96        40\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.97       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n",
            "Confusion matrix: [[33  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 28  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 33  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 33  0  1  0  0  0  0]\n",
            " [ 0  1  0  0 44  0  1  0  0  0]\n",
            " [ 0  0  1  0  0 44  1  0  0  1]\n",
            " [ 0  0  0  0  0  1 34  0  0  0]\n",
            " [ 0  0  0  0  0  1  0 33  0  0]\n",
            " [ 0  0  0  0  0  1  0  0 29  0]\n",
            " [ 0  0  0  1  0  0  0  0  1 38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Apply another classification algorithm named kNN, which is an instance classifcation model. \n",
        "*  3.1. Perform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "\n",
        "*   3.2. Then compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "Rti2y0Wz2KY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "gMO5x5LtnnXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbn32jQAjq0e",
        "outputId": "55249fcb-0de1-4011-97d3-42e04a64924a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ALeQgdgIjAnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "13LkkfpS2ZUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Lv74DjZfftna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = range(1, 30, 2)\n",
        "results = []\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "f1 = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy.append(accuracy_score(y_test, y_pred))\n",
        "    precision.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "    recall.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "    f1.append(f1_score(y_test, y_pred, average='weighted'))\n",
        "    results.append((k, accuracy))\n",
        "\n",
        "# select the best k value based on the accuracy score\n",
        "best_k = max(results, key=lambda x: x[1])[0]\n",
        "print(\"Best k value:\", best_k)"
      ],
      "metadata": {
        "id": "UnuvpWzukHEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40297ff4-b710-4bc5-87a7-d52a8d375d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best k value: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(f\"kNN Metrics for k={best_k}:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OoXbXnDuNOw",
        "outputId": "15ab3038-c662-4f42-8e54-19da409fda9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Metrics:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "kNN Metrics for k=1:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(k_values,accuracy,label='accuracy')\n",
        "plt.plot(k_values,precision,label='precision')\n",
        "plt.plot(k_values,recall,label='recall')\n",
        "plt.plot(k_values,f1,label='f1')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Wo2nX5OruPZK",
        "outputId": "89afed50-255f-4925-a3b3-abd57257cad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8f81030310>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Similar to Task 3, apply kNN algorithm to **mnist** dataset which included in datasets of sklearn API.\n",
        "*  4.1.\tPerform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "*  4.2.\tThen compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "X=mnist.data\n",
        "y=mnist.target\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2)"
      ],
      "metadata": {
        "id": "lH448fjFyNHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = list(range(1, 30, 2))\n",
        "results = []\n",
        "accurary= []\n",
        "precision = []\n",
        "recall = []\n",
        "f1 = []\n",
        "results_knn = []\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    predicted_outputs = knn.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accurary.append(accuracy_score(y_test, predicted_outputs))\n",
        "    precision.append(precision_score(y_test, predicted_outputs, average='macro'))\n",
        "    recall.append(recall_score(y_test, predicted_outputs, average='macro'))\n",
        "    f1.append(f1_score(y_test, predicted_outputs, average='macro'))\n",
        "\n",
        "    results_knn.append({'k': k, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1})"
      ],
      "metadata": {
        "id": "4_wASKMtyCQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_result_knn = max(results_knn, key=lambda x: x['f1'])\n",
        "\n",
        "print('Best k:', best_result_knn['k'])\n",
        "print('Accuracy:', best_result_knn['accuracy'])\n",
        "print('Precision:', best_result_knn['precision'])\n",
        "print('Recall:', best_result_knn['recall'])\n",
        "print('F1:', best_result_knn['f1'])\n"
      ],
      "metadata": {
        "id": "5ApI0XCupTjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d8c764-88ae-4489-c71a-eaa214cdbe32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best k: 1\n",
            "Accuracy: []\n",
            "Precision: [0.990625, 0.9941666666666666, 0.9910483870967741, 0.9860416666666666, 0.9860416666666666, 0.977267619456822, 0.9748144476286502, 0.9852083333333332, 0.9774324006267359, 0.9776056810752379, 0.9720279192605169, 0.9717961014420495, 0.9687377615787437, 0.9664729532163744, 0.9671165004903562]\n",
            "Recall: [0.9909722222222221, 0.9947916666666666, 0.9916666666666666, 0.9846955128205128, 0.9846955128205128, 0.9774038461538461, 0.9749038461538462, 0.9846955128205128, 0.9797916666666666, 0.9782017543859649, 0.974035087719298, 0.974035087719298, 0.9714035087719297, 0.9675573549257759, 0.9665156882591093]\n",
            "F1: [0.9904477100572766, 0.9943993287947036, 0.9911224058512962, 0.9848539939943606, 0.9848539939943606, 0.9767198670766588, 0.9740710382391257, 0.9845862366628302, 0.9782892905606259, 0.9774653735238517, 0.9725625224276053, 0.9725017011825734, 0.9695499477303887, 0.9663854597129594, 0.9659497267896938]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "predicted_outputs = logreg.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wj7aha6yVoc",
        "outputId": "3ef625f9-fcfe-4088-ea89-13d48936b61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, predicted_outputs)\n",
        "precision = precision_score(y_test, predicted_outputs, average='macro')\n",
        "recall = recall_score(y_test, predicted_outputs, average='macro')\n",
        "f1 = f1_score(y_test, predicted_outputs, average='macro')\n"
      ],
      "metadata": {
        "id": "sIqQDyPMyWG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(k_values,accurary,label='accuracy')\n",
        "plt.plot(k_values,precision,label='precision')\n",
        "plt.plot(k_values,recall,label='recall')\n",
        "plt.plot(k_values,f1,label='f1')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "K-rUHGXHzbL9",
        "outputId": "47cc6939-182f-4b50-9960-08e914260e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8f80c49880>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5. \n",
        "Compare the performance of selected classification algorithms (**Decision Treen, kNN, and Logistic Regression**) to ***spam detection***. The dataset can be accessed from the link: http://archive.ics.uci.edu/ml/datasets/Spambase \n",
        "Attribute Information:\n",
        "The last column of 'spambase.csv denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters. For the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes: \n",
        "*  48 continuous real [0,100] attributes of type word_freq_WORD \n",
        "= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string. **Example**: word_freq_address: percentage of words in the e-mail that match ADDRESS.\n",
        "*  6 continuous real [0,100] attributes of type char_freq_CHAR] \n",
        "= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
        "*  1 continuous real [1,...] attribute of type capital_run_length_average \n",
        "= average length of uninterrupted sequences of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_longest \n",
        "= length of longest uninterrupted sequence of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail\n",
        "*  1 nominal {0,1} class attribute of type spam = denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In order to compare the performance of selected algorithms, some common metrics including **accuracy, precision, recall, f1 measures** could be used.\n"
      ],
      "metadata": {
        "id": "MVzSk4l505E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spambase_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "headers = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\",\n",
        "           \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\",\n",
        "           \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\",\n",
        "           \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\",\n",
        "           \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\",\n",
        "           \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\",\n",
        "           \"word_freq_hp\", \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\",\n",
        "           \"word_freq_lab\", \"word_freq_labs\", \"word_freq_telnet\", \"word_freq_857\",\n",
        "           \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \"word_freq_technology\",\n",
        "           \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
        "           \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\",\n",
        "           \"word_freq_re\", \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\",\n",
        "           \"char_freq_;\", \"char_freq_(\", \"char_freq_[\", \"char_freq_!\", \"char_freq_$\",\n",
        "           \"char_freq_#\", \"capital_run_length_average\", \"capital_run_length_longest\",\n",
        "           \"capital_run_length_total\", \"spam\"]\n",
        "\n",
        "data5 = pd.read_csv(spambase_url, header=None, names=headers)"
      ],
      "metadata": {
        "id": "fEfRxan7Qs6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "bdhIea6gQs-3",
        "outputId": "2fc5d5d7-6ee4-45be-ccff-e106b1a7f83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
              "0               0.00               0.64           0.64           0.0   \n",
              "1               0.21               0.28           0.50           0.0   \n",
              "2               0.06               0.00           0.71           0.0   \n",
              "3               0.00               0.00           0.00           0.0   \n",
              "4               0.00               0.00           0.00           0.0   \n",
              "...              ...                ...            ...           ...   \n",
              "4596            0.31               0.00           0.62           0.0   \n",
              "4597            0.00               0.00           0.00           0.0   \n",
              "4598            0.30               0.00           0.30           0.0   \n",
              "4599            0.96               0.00           0.00           0.0   \n",
              "4600            0.00               0.00           0.65           0.0   \n",
              "\n",
              "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
              "0              0.32            0.00              0.00                0.00   \n",
              "1              0.14            0.28              0.21                0.07   \n",
              "2              1.23            0.19              0.19                0.12   \n",
              "3              0.63            0.00              0.31                0.63   \n",
              "4              0.63            0.00              0.31                0.63   \n",
              "...             ...             ...               ...                 ...   \n",
              "4596           0.00            0.31              0.00                0.00   \n",
              "4597           0.00            0.00              0.00                0.00   \n",
              "4598           0.00            0.00              0.00                0.00   \n",
              "4599           0.32            0.00              0.00                0.00   \n",
              "4600           0.00            0.00              0.00                0.00   \n",
              "\n",
              "      word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
              "0                0.00            0.00  ...        0.000        0.000   \n",
              "1                0.00            0.94  ...        0.000        0.132   \n",
              "2                0.64            0.25  ...        0.010        0.143   \n",
              "3                0.31            0.63  ...        0.000        0.137   \n",
              "4                0.31            0.63  ...        0.000        0.135   \n",
              "...               ...             ...  ...          ...          ...   \n",
              "4596             0.00            0.00  ...        0.000        0.232   \n",
              "4597             0.00            0.00  ...        0.000        0.000   \n",
              "4598             0.00            0.00  ...        0.102        0.718   \n",
              "4599             0.00            0.00  ...        0.000        0.057   \n",
              "4600             0.00            0.00  ...        0.000        0.000   \n",
              "\n",
              "      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
              "0             0.0        0.778        0.000        0.000   \n",
              "1             0.0        0.372        0.180        0.048   \n",
              "2             0.0        0.276        0.184        0.010   \n",
              "3             0.0        0.137        0.000        0.000   \n",
              "4             0.0        0.135        0.000        0.000   \n",
              "...           ...          ...          ...          ...   \n",
              "4596          0.0        0.000        0.000        0.000   \n",
              "4597          0.0        0.353        0.000        0.000   \n",
              "4598          0.0        0.000        0.000        0.000   \n",
              "4599          0.0        0.000        0.000        0.000   \n",
              "4600          0.0        0.125        0.000        0.000   \n",
              "\n",
              "      capital_run_length_average  capital_run_length_longest  \\\n",
              "0                          3.756                          61   \n",
              "1                          5.114                         101   \n",
              "2                          9.821                         485   \n",
              "3                          3.537                          40   \n",
              "4                          3.537                          40   \n",
              "...                          ...                         ...   \n",
              "4596                       1.142                           3   \n",
              "4597                       1.555                           4   \n",
              "4598                       1.404                           6   \n",
              "4599                       1.147                           5   \n",
              "4600                       1.250                           5   \n",
              "\n",
              "      capital_run_length_total  spam  \n",
              "0                          278     1  \n",
              "1                         1028     1  \n",
              "2                         2259     1  \n",
              "3                          191     1  \n",
              "4                          191     1  \n",
              "...                        ...   ...  \n",
              "4596                        88     0  \n",
              "4597                        14     0  \n",
              "4598                       118     0  \n",
              "4599                        78     0  \n",
              "4600                        40     0  \n",
              "\n",
              "[4601 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-956a4282-37e1-4f6a-9c1b-7d30a5bb969b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>...</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_!</th>\n",
              "      <th>char_freq_$</th>\n",
              "      <th>char_freq_#</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.142</td>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.555</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.404</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.147</td>\n",
              "      <td>5</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.250</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4601 rows × 58 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-956a4282-37e1-4f6a-9c1b-7d30a5bb969b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-956a4282-37e1-4f6a-9c1b-7d30a5bb969b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-956a4282-37e1-4f6a-9c1b-7d30a5bb969b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(\"spam\", axis=1)\n",
        "y = data[\"spam\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "c9-5wS1tQl4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Cq2sEQbBRo2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "knn = KNeighborsClassifier()\n",
        "lr = LogisticRegression()\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "knn.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "vKngwv_2Rxrs",
        "outputId": "4cb5bfe8-7761-46df-f68c-cd3513768279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "dt_preds = dt.predict(X_test)\n",
        "knn_preds = knn.predict(X_test)\n",
        "lr_preds = lr.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_preds))\n",
        "print(\"Decision Tree Precision:\", precision_score(y_test, dt_preds))\n",
        "print(\"Decision Tree Recall:\", recall_score(y_test, dt_preds))\n",
        "print(\"Decision Tree F1 Score:\", f1_score(y_test, dt_preds))\n",
        "print(\"Decision Tree ROC AUC Score:\", roc_auc_score(y_test, dt_preds))\n",
        "\n",
        "print(\"k-NN Accuracy:\", accuracy_score(y_test, knn_preds))\n",
        "print(\"k-NN Precision:\", precision_score(y_test, knn_preds))\n",
        "print(\"k-NN Recall:\", recall_score(y_test, knn_preds))\n",
        "print(\"k-NN F1 Score:\", f1_score(y_test, knn_preds))\n",
        "print(\"k-NN ROC AUC Score:\", roc_auc_score(y_test, knn_preds))\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, lr_preds))\n",
        "print(\"Logistic Regression Precision:\", precision_score(y_test, lr_preds))\n",
        "print(\"Logistic Regression Recall:\", recall_score(y_test, lr_preds))\n",
        "print(\"Logistic Regression F1 Score:\", f1_score(y_test, lr_preds))\n",
        "print(\"Logistic Regression ROC AUC Score:\", roc_auc_score(y_test, lr_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1ZfVOO8R5X0",
        "outputId": "7922c2b9-b66b-4dc0-fb1e-6a3ac51b3eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9065894279507604\n",
            "Decision Tree Precision: 0.8957597173144877\n",
            "Decision Tree Recall: 0.878682842287695\n",
            "Decision Tree F1 Score: 0.8871391076115486\n",
            "Decision Tree ROC AUC Score: 0.9026498788552904\n",
            "k-NN Accuracy: 0.8964518464880521\n",
            "k-NN Precision: 0.8931159420289855\n",
            "k-NN Recall: 0.854419410745234\n",
            "k-NN F1 Score: 0.8733392382639503\n",
            "k-NN ROC AUC Score: 0.8905181630840597\n",
            "Logistic Regression Accuracy: 0.9225199131064447\n",
            "Logistic Regression Precision: 0.933579335793358\n",
            "Logistic Regression Recall: 0.8769497400346621\n",
            "Logistic Regression F1 Score: 0.90437890974084\n",
            "Logistic Regression ROC AUC Score: 0.9160868103158386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7Dxl4E_Rz0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}